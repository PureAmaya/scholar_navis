import os
import yaml
import glob
import shutil
from datetime import datetime
from shared_utils.scholar_navis.other_tools import generate_download_file
from shared_utils.scholar_navis.const_and_singleton import VERSION
from time import sleep,time
from shared_utils.scholar_navis import pdf_reader
from shared_utils.scholar_navis.multi_lang import _
from multiprocessing import cpu_count
from threading import Lock
from concurrent.futures import ThreadPoolExecutor
from .tools.common_plugin_para import common_plugin_para
from toolbox import CatchException, get_log_folder, get_user, update_ui, update_ui_lastest_msg
from .tools.article_library_ctrl import check_library_exist_and_assistant, lib_manifest, pdf_yaml,markdown_to_pdf
from crazy_functions.crazy_utils import request_gpt_model_in_new_thread_with_ui_alive, request_gpt_model_multi_threads_with_very_awesome_ui_and_high_efficiency

lock = Lock()

@check_library_exist_and_assistant(accept_nonexistent=False, accept_blank=False)
@CatchException
def æŒ‰å…³é”®è¯æ€»ç»“æ–‡çŒ®(txt, llm_kwargs, plugin_kwargs, chatbot, history, system_prompt, user_request):
    """
    å°†analyzedä¸­çš„æ‰€æœ‰æ–‡ç« è¿›è¡Œç»Ÿä¸€æ€»ç»“

    åç»­è‡ªå·±å†™ä¸€ä¸ªgradioï¼Œè„±ç¦»ç°åœ¨ç”¨äºå¯¹è¯çš„UI

    txt: è¾“å…¥æ ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ï¼Œä¾‹å¦‚éœ€è¦ç¿»è¯‘çš„ä¸€æ®µè¯ï¼Œå†ä¾‹å¦‚ä¸€ä¸ªåŒ…å«äº†å¾…å¤„ç†æ–‡ä»¶çš„è·¯å¾„
    llm_kwargs: gptæ¨¡å‹å‚æ•°, å¦‚æ¸©åº¦å’Œtop_pç­‰, ä¸€èˆ¬åŸæ ·ä¼ é€’ä¸‹å»å°±è¡Œ
    plugin_kwargs: æ’ä»¶çš„å‚æ•°
    chatbot: èŠå¤©æ˜¾ç¤ºæ¡†çš„å¥æŸ„ï¼Œç”¨äºæ˜¾ç¤ºç»™ç”¨æˆ·ï¼Œä¸€æ—¦åˆ†è¡Œï¼ˆè¾“å…¥é€—å·ï¼‰å°±æ¢è¯´è¯äºº
    history: èŠå¤©å†å²ï¼Œå‰æƒ…æè¦
    system_prompt: ç»™gptçš„é™é»˜æé†’
    user_request: å½“å‰ç”¨æˆ·çš„è¯·æ±‚ä¿¡æ¯ï¼ˆIPåœ°å€ç­‰ï¼‰
    """

    # < --------------------è¯»å–æ’ä»¶çš„å‚æ•°--------------- >
    library_name = plugin_kwargs['lib']
    # GPTåå¥½è¯­è¨€
    GPT_prefer_language = plugin_kwargs['gpt_prefer_lang']
    # å‘½ä»¤è·å–
    command = plugin_kwargs['command']

    # è¿™ä¸ªæ€»ç»“åº“çš„æ ¹ç›®å½•
    this_library_root_dir = os.path.join(get_log_folder(
        user=get_user(chatbot), plugin_name='scholar_navis'), library_name)
    # ç¼“å­˜æ–‡ä»¶å¤¹
    cache_dir = os.path.join(this_library_root_dir, "cache")
    # å¤„ç†å®Œçš„pdfæ‰€åœ¨çš„æ–‡ä»¶å¤¹ï¼ˆå½’æ¡£å’¯ï¼‰
    repo_dir = os.path.join(this_library_root_dir, "repository")
    summarization_file_fp = os.path.join(
        this_library_root_dir, "summarization.txt")
    summarization_pdf_fp = f'{summarization_file_fp[:-4]}.pdf'

    # è¯»ä¸€ä¸‹ç°åœ¨çš„å…³é”®è¯ï¼ˆå¾—åˆ°çš„æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼‰
    with open(os.path.join(this_library_root_dir, 'lib_manifest.yml'), 'r') as f:
        keywords = yaml.safe_load(f)[lib_manifest.key_words.value]
    # å¦‚æœå…³é”®è¯æ²¡æœ‰ï¼Œç»ˆæ­¢æµç¨‹
    if len(keywords) == 0:
            # æ²¡å®Œæˆå·¥ä½œï¼Œå¼€å§‹æ€»ç»“æµç¨‹
        chatbot.append([_("æ€»ç»“ç»ˆæ­¢ã€‚æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„å…³é”®è¯"),
                    _("è¯·åœ¨ <b>ç¼“å­˜pdfæ–‡çŒ®</b> ä¸­è®¾å®šå…³é”®è¯")])
        yield from update_ui(chatbot=chatbot, history=[]) 
        return

    # < --------------------------------------------äº‹å‰å‡†å¤‡----------------------------------------------- >

    # åˆ¤æ–­æœ¬å·¥å…·çš„å·¥ä½œæµæ˜¯å¦å®Œæˆï¼ˆè¯¥æœ‰çš„æ–‡ä»¶æœ‰äº†ï¼Œè¯¥ç§»åŠ¨èµ°çš„æ–‡ä»¶ç§»èµ°äº†ï¼‰ã€‚
    # é˜²æ­¢é‡é‡å¤é¢„å¤„ç†
    pdfs_in_cache = glob.glob(os.path.join(cache_dir,"*.pdf"))
    pdf_yamls_in_cache = glob.glob(os.path.join(cache_dir,"*.yml"))
    pdfs_in_repo =  glob.glob(os.path.join(repo_dir,"*.pdf")) # æµ‹è¯•è¿‡äº†ï¼Œè·¯å¾„ä¸å­˜åœ¨è¿”å›[]
    workflow_done = os.path.exists(summarization_file_fp)

    # å®Œæˆäº†æ‰€æœ‰çš„å·¥ä½œ
    if workflow_done:
        # å¼ºåˆ¶é‡æ–°åˆ†æçš„è¯ï¼ŒæŒ‰ç…§æ­£å¸¸æµç¨‹æ¥å°±å¯ä»¥äº†
        if command == 'force':
            pass
        # æ²¡æœ‰å¼ºåˆ¶é‡æ–°åˆ†æï¼Œå°±æé†’ä¸€ä¸‹
        else:
            # è¯»ä¸€ä¸‹æ­¤å‰æ€»ç»“çš„å†…å®¹
            with open(summarization_file_fp, "r", encoding='utf-8') as file:
                line1 = _(
                    'æ€»ç»“åº“ <b>{name}</b> å·²ç»åˆ†æå®Œæ¯•ï¼Œå¯ä»¥ä½¿ç”¨<b>ä¸AIäº¤æµç ”ç©¶è¿›å±•</b>è¿›ä¸€æ­¥äº†è§£è¯¥æ–¹é¢çš„ç ”ç©¶ç°çŠ¶ï¼Œå¦‚æœå¾—åˆ°äº†æŸç¯‡æ„Ÿå…´è¶£çš„æ–‡ç« ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ <b>ç²¾ç»†åˆ†ææ–‡çŒ®</b> è¿›è¡Œç²¾è¯»').format(name=library_name)
                line2 = _('å‚è€ƒå…³é”®è¯')
                line3 = _('å¦‚æœå¯¹åˆ†æç»“æœä¸æ»¡æ„ï¼Œå¯ä»¥é€‰æ‹©å¼ºåˆ¶é‡æ–°åˆ†æï¼ˆä»…å¯¹æœ€ç»ˆæ€»ç»“ç”Ÿæ•ˆï¼‰')
                line4 = _(
                    '<b>æ³¨æ„ï¼š</b>æ‰§è¡Œæ­¤æ“ä½œä¼š<font color=red>åˆ é™¤æ­¤å‰çš„æ€»ç»“</font>ï¼ˆä¸ä¼šå½±å“é¢„å¤„ç†å’Œé¢„åˆ†æçš„ç»“æœï¼‰ã€‚å¦‚æœå¯¹æ­¤å‰çš„æ€»ç»“ä¸æ»¡æ„å†ä½¿ç”¨! ')
                line5 = _('ä¸‹é¢æ˜¯æ­¤å‰çš„æ€»ç»“å†…å®¹: ')
                chatbot.append([f"{line1}<br>\
                                <br><ul><li>{line2}: {', '.join(keywords)}</li>\
                                <li>{line3}</li>\
                                <li>{line4}</li></ul>",
                                line5])
                
                summarization_content = file.read()
                # å‡å¦‚pdfæ²¡äº†ï¼Œç”Ÿæˆä¸€ä¸ª
                if not os.path.exists(summarization_pdf_fp):
                    markdown_to_pdf(summarization_content,'summarization',os.path.dirname(summarization_pdf_fp))
                chatbot.append([summarization_content,generate_download_file(summarization_pdf_fp,_('ç‚¹å‡»è¿™é‡Œä¸‹è½½pdfæ ¼å¼çš„æ€»ç»“å†…å®¹'))])
                # æé†’ä¸€ä¸‹ä¸èƒ½ç”¨çš„PDF
                chatbot.append(_unusable_pdf_message(this_library_root_dir))
                # æé†’ä¸€ä¸‹ä¸èƒ½å¯¹è¯
                chatbot.append([_('è¯·æ³¨æ„ï¼Œæœ¬åŠŸèƒ½ä¸æ”¯æŒå¯¹è¯ã€‚'),_('å¦‚æœè¦ä½¿ç”¨å¯¹è¯åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨ <b>ä¸AIäº¤æµç ”ç©¶è¿›å±•</b>')])
            yield from update_ui(chatbot=chatbot, history=[])  # åˆ·æ–°ç•Œé¢
            return

    # æ²¡å®Œæˆå·¥ä½œï¼Œå¼€å§‹æ€»ç»“æµç¨‹
    chatbot.append([_("ç°åœ¨å°†å¯¹{}ä¸­çš„æ–‡çŒ®è¿›è¡Œæ€»ç»“åˆ†æ").format(library_name),
                    _("åˆ†æå‚è€ƒçš„å…³é”®è¯æ˜¯ {}ã€‚ä¸ºåŠ å¿«é€Ÿåº¦ï¼Œé»˜è®¤ <b>ä»…å¯¹æ‘˜è¦</b> è¿›è¡Œæ€»ç»“").format(', '.join(keywords))])
    yield from update_ui(chatbot=chatbot, history=[])  # åˆ·æ–°ç•Œé¢

    # < ---------ï¼ˆæ”¯æŒä¸­æ–­ï¼‰é¢„å¤„ç†ï¼šå¯¹ç¼“å­˜ä¸­çš„pdfé¢„å¤„ç†ï¼ˆè·å–æ ‡é¢˜ï¼Œæ‘˜è¦ï¼Œå‚è€ƒæ–‡çŒ®ï¼‰ï¼Œæ–¹ä¾¿åç»­æ‰¹é‡é—®GPTï¼Œä¸è¿›è¡Œæ–‡ä»¶ç§»åŠ¨---------- >
    # è¿™é‡Œçš„ä¸­æ–­æ˜¯æŒ‡ï¼Œæ‰€æœ‰æ²¡æœ‰yamlçš„éƒ½è¢«è§†ä¸ºæ²¡æœ‰é¢„å¤„ç†ï¼Œåªè¦å‘ç”Ÿäº†é¢„å¤„ç†ï¼Œå°±ä¼šæœ‰yaml

        
    # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰å¾…åˆ†æçš„pdfæ–‡ä»¶
    if len(pdfs_in_cache) < 1:
        # ä¹Ÿæ²¡æœ‰é¢„å¤„ç†å®Œçš„æ–‡ç« 
        if len(pdfs_in_repo) < 1:
            yield from update_ui_lastest_msg(_('è¯¥æ€»ç»“åº“ä¸­æ²¡æœ‰ä»»ä½•å¯ç”¨çš„pdfæ–‡ç« ã€‚å¦‚æœéœ€è¦è¿›è¡Œæ€»ç»“åˆ†æï¼Œè¯·å…ˆä½¿ç”¨ <b>ç¼“å­˜pdfæ–‡çŒ®</b> æ·»åŠ æ–°çš„æ–‡ç« '), chatbot, [])
            return

        # å·²ç»æœ‰åˆ†æè¿‡çš„æ–‡ç« äº†ï¼Œç¼“å­˜é‡Œåˆæ²¡æœ‰æ–°çš„è¯´æ˜é¢„å¤„ç†å®Œæˆäº†
        else:
            chatbot.append(
                [_("æ²¡æœ‰æ–°çš„æ–‡ç« éœ€è¦é¢„å¤„ç†æˆ–å·²é¢„å¤„ç†å®Œæˆ"),
                 _("ç›®å‰å·²ç»æœ‰<b>{}ç¯‡æ–‡ç« </b>é¢„å¤„ç†å®Œæ¯•ï¼Œå³å°†è¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œ...").format(len(pdfs_in_repo))])
            yield from update_ui(chatbot=chatbot, history=history)  # åˆ·æ–°ç•Œé¢

    # å¦‚æœç¼“å­˜ä¸­æœ‰å¾…åˆ†æçš„pdfæ–‡ä»¶ï¼Œé‚£å°±å…ˆé¢„å¤„ç†å§
    # é’ˆå¯¹é‡æ–°åˆ†æï¼Œæ­¤æ—¶å·¥ä½œæµå·²ç»å®Œæˆï¼ŒåŠæ—¶cacheä¸­æœ‰æ²¡æœ‰åˆ†æçš„æ–‡ç« ï¼ˆä¸€èˆ¬æ˜¯ä¸èƒ½ç”¨çš„ï¼‰ï¼Œä¹Ÿè·³è¿‡
    elif not workflow_done:
        
        timer = 0
        
        def _preprocess_multithread(pdfs_fp: list[str]):
            """ç»™ é€‰å®šçš„pdfä»¬ æä¾›å¤šçº¿ç¨‹ç”¨è·å–PDFä¿¡æ¯ï¼ˆå³æ‰€è°“çš„â€œé¢„å¤„ç†â€ï¼‰
            Args:
                pdfs_fp (list[str]):éœ€è¦é¢„å¤„ç†çš„pdfä»¬

            """
            # è·å–pdfçš„æ ‡é¢˜ã€æ‘˜è¦ï¼ˆå¹¶ä¸”ä¼šåœ¨pdfæ—è¾¹ç”Ÿæˆä¸€ä¸ªè®°å½•è¿™äº›å†…å®¹çš„ymlï¼Œæ–‡ä»¶åä¸pdfä¸€è‡´ï¼‰
            _pdf_manifests_fp = []

            for pdf_fp in pdfs_fp:
                # å¦‚æœè¶…æ—¶ï¼Œå°±ä¸è·å–äº†
                if time() - timer > 2:
                    sleep(0.1)
                    if time() - timer > 2:
                        return []
                    '''ä¸ºä½•åˆç¡äº†0.1sï¼š
                        å®è·µè¿‡ç¨‹ä¸­å‘ç°ï¼Œå½“æ•°æ®åº“ä¸å­˜åœ¨æ—¶ï¼Œæœ‰çš„çº¿ç¨‹åˆšå¯åŠ¨ï¼Œtime() - timerå°±å¤§äº2säº†ï¼Œè¿™æ ·ä¼šä½¿çº¿ç¨‹æ„å¤–ç»ˆæ­¢ï¼ˆå³ä½¿çˆ¶çº¿ç¨‹è¿˜åœ¨è¿è¡Œï¼‰
                        ç„¶åæˆ‘æƒ³ï¼Œè¿™ä¸ªç°è±¡ä¼šä¸ä¼šæ˜¯å› ä¸ºå­çº¿ç¨‹è¿™é‡Œçš„timerè¿˜æ²¡ååº”è¿‡æ¥
                        äºæ˜¯å°±å†ç¡0.1sï¼ˆåæ­£ä¹Ÿä¸é•¿ï¼Œæ„ŸçŸ¥ä¸æ˜æ˜¾ï¼‰
                        å¦‚æœè¿‡äº†0.1sï¼Œè¿˜æ˜¯è¶…æ—¶çš„ï¼Œè¯´æ˜çˆ¶çº¿ç¨‹çœŸçš„æŒ‚äº†ï¼Œé‚£ä¹ˆå­çº¿ç¨‹åœä¸‹æ¥å°±è¡Œ
                        åä¹‹ï¼Œå¦‚æœä¸è¶…æ—¶äº†ï¼Œé‚£å°±ç»§ç»­æ­£å¸¸çš„è¿è¡Œä¸‹å»å°±è¡Œ
                        è¿™é‡Œçš„ä»£ç è¿è¡ŒæŒºå¿«çš„ï¼ˆç¼“å­˜ + æ¯”è¾ƒå¿«çš„LLMï¼Œé€šå¸¸æƒ…å†µä¸‹èƒ½æŠŠcacheä¸­çš„pdfå…¨éƒ½é¢„å¤„ç†å®Œæˆï¼‰
                        é€šè¿‡æç«¯æµ‹è¯•ï¼ˆæ€»æ˜¯ä½¿ç”¨AIè¾…åŠ© + max_workers = 1 + è¶…æ—¶1sï¼‰ï¼Œæµ‹è¯•æ˜¯å¯ä»¥æ­£å¸¸ç»ˆæ­¢çš„
                    '''
                
                # å¦‚æœæœ‰yamläº†ï¼Œä¹Ÿå°±æ²¡æœ‰å¿…è¦è¿›è¡Œé¢„å¤„ç†äº†
                if os.path.exists(f'{pdf_fp[:-4]}.yml'):
                    _pdf_manifests_fp.append(f'{pdf_fp[:-4]}.yml')
                    continue
                
                # æ²¡æœ‰yamlï¼Œå°±è·å–ä¸€ä¸ªå§
                usable,_1, pdf_manifest_fp = pdf_reader.get_pdf_inf(pdf_fp,plugin_kwargs['ai_assist'],llm_kwargs)
                # å‚¨å­˜æ‰€æœ‰çš„æ¸…å•æ–‡ä»¶è·¯å¾„
                if usable: _pdf_manifests_fp.append(pdf_manifest_fp)
                else :
                    with lock:
                        _unusable_pdf_message(lib_dir=this_library_root_dir,unusable_pdf_fp=pdf_fp)
                
            return _pdf_manifests_fp
        
        # å¤šçº¿ç¨‹é¢„å¤„ç†
        max_workers = cpu_count()
        if plugin_kwargs['ai_assist']:max_workers = 3 # å¦‚æœæœ‰è®¿é—®AIçš„æƒ…å†µï¼Œé™åˆ¶ä¸€ä¸‹ï¼Œé˜²æ­¢è¶…å‡ºæœ€å¤§å¹¶å‘
        with ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix='article-preprogress-') as executor:
            # æŒ‰ç…§æ ¸å¿ƒæ•°åˆ’åˆ†éœ€è¦è¿›è¡Œé¢„å¤„ç†çš„pdf
            # æ¯ä¸€ç»„é‡Œé¢æœ‰å‡ ç¯‡æ–‡ç« ï¼ˆå¯¹äºä¸€äº›å·²ç»æœ‰yamlçš„ï¼Œä¸éœ€è¦é‡å¤åˆ†æï¼‰
            group_mumber_count = int(len(pdfs_in_cache)/ cpu_count())
            if group_mumber_count == 0:
                group_mumber_count = 1
            # åˆ’åˆ†æˆå‡ ç»„ï¼Œæ¯ä¸€ä¸ªtaskéƒ½å¤„ç†ä¸€ç»„pdfé¢„å¤„ç†çš„ä»»åŠ¡
            # åˆ†ç»„æ•°=CPUæ ¸å¿ƒæ•°
            # æ¯ä¸ªæ ¸å¿ƒéƒ½åˆ†ä¸€ç‚¹æ´»å¹²
            group_pdfs_in_cache_wait_process_path = [
                pdfs_in_cache[i:i+group_mumber_count] for i in range(0, len(pdfs_in_cache), group_mumber_count)]
            tasks = []
            for each in group_pdfs_in_cache_wait_process_path:
                timer = time() # ä¸åŠ ä¸è¡Œ
                tasks.append(executor.submit(_preprocess_multithread, each))

            # ç­‰å¾…ä»»åŠ¡æ‰§è¡Œå®Œæ¯•
            chatbot.append([_('ç›®å‰æœ‰{pdf_count}ç¯‡æ–‡ç« å¤„äºç¼“å­˜ä¸­ï¼ˆå®é™…éœ€è¦é¢„å¤„ç†{jb}ç¯‡ï¼Œ{done}ç¯‡å·²ç»å®Œæˆæµç¨‹ï¼‰ï¼Œå³å°†ä½¿ç”¨{cpu}ä¸ªçº¿ç¨‹è¿›è¡Œé¢„å¤„ç†ã€‚å…¨éƒ¨é¢„å¤„ç†å®Œæˆåå°±ä¼šä½¿ç”¨GPTè¿›è¡Œæ±‡æ€»åˆ†æ...')
                            .format(pdf_count=len(pdfs_in_cache),jb= len(pdfs_in_cache) - len(pdf_yamls_in_cache),done = len(pdfs_in_repo),cpu=cpu_count()),
                            _('é¢„å¤„ç†ä¸­....')])
            yield from update_ui(chatbot=chatbot, history=history)
            
            while True:
                task_done_num = 0
                for task in tasks:
                    if task.done():
                        task_done_num += 1
                
                yield from update_ui_lastest_msg(_('ä»»åŠ¡åˆ†ç»„ [{done_num}/{task_total}] é¢„å¤„ç†ä¸­...')
                                                .format(done_num=task_done_num, task_total=len(tasks)), chatbot, [])
                # å¤„ç†å®Œäº†ï¼Ÿ
                if task_done_num == len(tasks):break
                sleep(0.1)
                timer = time()

        pdf_manifests_fp = []
        for task in tasks:
            # è·å–pdfçš„æ ‡é¢˜ã€æ‘˜è¦å’Œä¸€ä½œï¼ˆå¹¶ä¸”ä¼šåœ¨pdfæ—è¾¹ç”Ÿæˆä¸€ä¸ªè®°å½•è¿™äº›å†…å®¹çš„ymlï¼Œæ–‡ä»¶åä¸pdfä¸€è‡´ï¼‰
            _pdf_manifest_fp = task.result() # 
            # å‚¨å­˜æ‰€æœ‰çš„æ¸…å•æ–‡ä»¶è·¯å¾„
            pdf_manifests_fp.extend(_pdf_manifest_fp)

        yield from update_ui_lastest_msg(_('ç¼“å­˜æ–‡ç« é¢„å¤„ç†å®Œæˆ'), chatbot=chatbot, history=history)
        chatbot.append(_unusable_pdf_message(lib_dir=this_library_root_dir))
        #  æ³¨æ„ï¼Œé¢„å¤„ç†å®Œæˆåçš„pdfä»ç„¶åœ¨cacheæ–‡ä»¶å¤¹ä¸­ï¼ˆä½†æ˜¯ä¼šå¤šä¸€ä¸ªpdfæ¸…å•æ–‡ä»¶md5.ymlï¼‰ï¼Œå› ä¸ºä»–ä»¬è¿˜æ²¡æœ‰ç»è¿‡GPTåˆ†æ
        #  æ€»ç»“å®Œæ‘˜è¦çš„æ–‡ç« ä¼šåœ¨repoä¸­ï¼Œå¹¶ä¸”æœ€åçš„æ€»ç»“æ€§å†…å®¹åªä¼šæŠŠpdf_ymlä¸­çš„analysiså–‚ç»™AI
        #  è¿™æ ·å­å°±å¯ä»¥å®ç°é¢„å¤„ç†ç»“æŸåé—®AIçš„é˜¶æ®µâ€œæ–­ç‚¹ç»­ä¼ â€äº†

    # < -------ï¼ˆç»„é—´æ”¯æŒä¸­æ–­ï¼‰é¢„åˆ†æï¼šä½¿ç”¨GPTï¼Œå¯¹æ¯ç»„çš„pdfæ‘˜è¦è¿›è¡Œå•ç‹¬åˆ†æï¼ˆè®¾å®škeywords_analysiså€¼ï¼‰ï¼Œä¹‹åä¼šç§»åŠ¨åˆ°repoæ–‡ä»¶å¤¹ä¸­------------ >
    # è¯¦ç»†è¯´ä¸€ä¸‹å•Šï¼Œè¿™é‡Œçš„ä¸­æ–­æ˜¯æŒ‡ï¼Œåœ¨repoé‡Œçš„ä¸ºå¤„ç†å®Œçš„ï¼Œä¸ä¼šè¿›è¡Œåˆ†æ
    # æ‰€æœ‰åœ¨cacheä¸­ï¼Œæ— è®ºæ˜¯å¦æœ‰è¢«åˆ†æè¿‡çš„ï¼Œéƒ½ä¼šè¿›è¡Œåˆ†æ
    # åæ­£å·®åˆ«å°±5ä¸ªäº†ï¼ŒğŸ’©å±±å…ˆè¿™ä¸ªæ ·å­å§

        chatbot.append([_("ç°åœ¨å¼€å§‹ä½¿ç”¨GPTè¿›è¡Œé¢„å…ˆåˆ†æï¼Œæ¯5ä¸ªæ–‡ç« ä¸€ç»„,æ€»å…±æœ‰<b>{}</b>ç¯‡æ–‡ç« ").format(len(pdf_manifests_fp)),
                        _("æ­¤è¿‡ç¨‹ä¸­å¯ä»¥éšæ—¶å…³é—­è¯¥é¡µé¢ï¼Œä¸‹æ¬¡ä¼šä» <b>ä¸­æ–­çš„åˆ†ç»„</b> å¼€å§‹")])
        yield from update_ui(chatbot=chatbot, history=history)  # åˆ·æ–°ç•Œé¢

        # å¯¹æ¯5ä¸ªpdfæ¸…å•ï¼ˆmd5.ymlï¼‰è¿›è¡Œæ€»ç»“åˆ†æ
        # ç¡®å®šèƒ½å¤Ÿåˆ†æˆå¤šå°‘ä¸ªæ‰¹æ¬¡
        num_batches = len(pdf_manifests_fp) // 5 if len(pdf_manifests_fp) >= 5 else 1
        
        if num_batches == 0:
            yield from update_ui_lastest_msg(_('åˆ†æç»ˆæ­¢ï¼å› ä¸ºæŸäº›åŸå› ï¼Œç¨‹åºå¹¶æ²¡æœ‰æ‰¾åˆ°å¯ä»¥æ€»ç»“åˆ†æçš„å†…å®¹'), chatbot=chatbot, history=[])
            return

        # åˆ’åˆ†åˆ—è¡¨ä¸ºåŒ…å«5ä¸ªå…ƒç´ çš„æ‰¹æ¬¡
        batches = []
        for i in range(num_batches):
            # print("operation start!")
            start_index = i * 5
            # è¿˜æ²¡æœ‰åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„batchï¼Œbatch5ä¸ªå†…å®¹å°±å¯ä»¥
            if i < num_batches - 1:
                batch = pdf_manifests_fp[start_index:start_index + 5]
            # åˆ°äº†æœ€åä¸€ä¸ªbatchäº†ï¼Œå°±æŠŠå‰©ä¸‹ä¸è¶³5ä¸ªçš„å†…å®¹ä¹Ÿå½’çº³è¿›æ¥ï¼Œå°±æ˜¯æœ€åä¸€ä¸ªbatchå¯èƒ½æœ‰åå¤šä¸ªå†…å®¹äº†
            else:
                batch = pdf_manifests_fp[start_index:]
            batches.append(batch)

        # å¯¹æ¯ä¸ªpatchè¿›è¡ŒGPT é¢„åˆ†æ
        for index, batch in enumerate(batches):
            
            # å…ˆå¯¹æ¯ä¸ªæ–‡ç« çš„æ‘˜è¦å•ç‹¬åˆ†æä¸€ä¸‹
            # è¿™æ ·å­åšå¯ä»¥ç²¾ç‚¼éœ€è¦çš„ä¿¡æ¯ï¼Œè¿˜å¯ä»¥å»é™¤æå–abstractè¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¸€äº›æ— ç”¨æ–‡æœ¬
            yield from _analyze_abstract_gpt(batch, keywords, index + 1, len(batches), llm_kwargs, GPT_prefer_language,
                                              chatbot, history, system_prompt, user_request)

            # å½“å‰æ‰¹æ¬¡çš„æ–‡ç« åˆ†æå®Œæˆåï¼Œå°±å¯ä»¥ç§»åŠ¨åˆ°analyzedæ–‡ä»¶å¤¹äº†
            # ç§»åŠ¨ä¹‹åå°±ä¸åœ¨cacheæ–‡ä»¶å¤¹äº†ï¼Œé˜²æ­¢å¤šæ¬¡é‡å¤åˆ†æ
            for _pdf_manifest_fp in batch:
                filename,_1 = os.path.splitext(os.path.basename(_pdf_manifest_fp))
                yml_destination = os.path.join(
                    repo_dir, filename + '.yml')
                pdf_destination = os.path.join(
                    repo_dir, filename + '.pdf')
                # pdfè·¯å¾„
                pdf_fp = os.path.join(os.path.dirname(
                    _pdf_manifest_fp), filename + '.pdf')
                try:
                    os.makedirs(repo_dir, exist_ok=True)
                    shutil.move(pdf_fp, pdf_destination)
                    shutil.move(_pdf_manifest_fp, yml_destination)
                except IOError as e:
                    raise IOError(_("ç§»åŠ¨æ–‡ä»¶æ—¶å‡ºé”™ï¼š{}").format(str(e)))

    # æ‰€æœ‰æ–‡ç« ã€æŒ‰ç…§æ‰€æœ‰çš„å…³é”®è¯éƒ½åˆ†æå®Œäº†ï¼Œå°±å¼€å§‹æœ€åçš„æ€»ç»“äº†

    # < ---- ---- ---- -------æ€»ç»“ï¼Œï¼ˆrepoæ–‡ä»¶å¤¹å†…æ‰€æœ‰çš„yamlï¼‰å…·ä½“çš„æ‰§è¡Œè¿‡ç¨‹å¦‚ä¸‹ï¼š----- ---- ---- ---- ---- ----------- >

    chatbot.append([_('æ­£åœ¨æ€»ç»“ï¼Œæ€»ç»“è¿‡ç¨‹ä¸­ï¼Œè¯·ä¸è¦å…³é—­è¯¥é¡µé¢...'), _('å¤„ç†ä¸­....')])
    yield from update_ui(chatbot=chatbot, history=[])

    result = yield from _summarize_all_paper(this_library_root_dir, llm_kwargs, GPT_prefer_language, chatbot, [], system_prompt, user_request)

    # å››ä¸ªğŸã€‚å»é™¤ä»£ç å—
    result = result.replace('```','')

    # å†™æˆtxt
    with open(summarization_file_fp, 'w', encoding='utf-8') as f:
        f.write(result)

    # pdfæ¨é€ä¸‹è½½
    if os.path.exists(summarization_pdf_fp): os.remove(summarization_pdf_fp)
    markdown_to_pdf(result,'summarization',os.path.dirname(summarization_pdf_fp))

    chatbot.clear()
    chatbot.append([_('æ€»ç»“å®Œæˆã€‚ä¸‹é¢æ˜¯æ€»ç»“çš„å†…å®¹: ï¼ˆä¸æ”¯æŒå¯¹è¯ï¼‰') , 
                    '<ul><li>' +
                    _('å›´ç»•ç€å…³é”®è¯ï¼š{}').format(", ".join(keywords)) +
                    '</li><li>' +
                    _('å¦‚æœä¸æ»¡æ„ç”Ÿæˆçš„ç»“æœï¼ˆä¾‹å¦‚å†…å®¹æ˜æ˜¾ç¼ºå¤±ï¼‰ï¼Œå¯ä»¥ä½¿ç”¨å°è¯•é‡æ–°ç”Ÿæˆ') + 
                    '</li></ul>']) 
    
    chatbot.append([result,generate_download_file(summarization_pdf_fp,_('ç‚¹å‡»è¿™é‡Œä¸‹è½½pdfæ ¼å¼çš„æ€»ç»“å†…å®¹'))])
    chatbot.append(_unusable_pdf_message(lib_dir=this_library_root_dir))
    # æé†’ä¸€ä¸‹ä¸èƒ½å¯¹è¯
    chatbot.append([_('è¯·æ³¨æ„ï¼Œæœ¬åŠŸèƒ½ä¸æ”¯æŒå¯¹è¯ã€‚'),_('å¦‚æœè¦ä½¿ç”¨å¯¹è¯åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨ <b>ä¸AIäº¤æµç ”ç©¶è¿›å±•</b>')])
    yield from update_ui(chatbot=chatbot, history=[])

execute = æŒ‰å…³é”®è¯æ€»ç»“æ–‡çŒ® # ç”¨äºçƒ­æ›´æ–°

def _analyze_abstract_gpt(pdf_manifests_fp: list, keywords: list[str], start_batch: int, total_batch: int, llm_kwargs, GPT_prefer_language, chatbot, history, system_prompt, user_request):
    """ å¯¹æä¾›çš„æ¯ä¸ªpdfçš„æ‘˜è¦è¿›è¡Œé¢„åˆ†æï¼Œå¹¶å°†åˆ†æç»“æœå†™åˆ°pdfæ¸…å•ï¼ˆmd5.ymlï¼‰ä¸­
        ç°åœ¨ä¸»è¦æ˜¯ç”¨äºé¢„åˆ†æï¼Œä»¥åå¯èƒ½ä¹Ÿæœ‰å…¶ä»–çš„åŠŸèƒ½å§

    Args:
        pdf_manifests_fp (list): pdfæ¸…å•ï¼ˆmd5.ymlï¼‰åˆ—è¡¨
        keywords (list[str]): å…³é”®è¯åºåˆ—
        start_batch (int): è¿™æ˜¯ç¬¬å‡ ä¸ªbatch
        total_count (int): æ€»å…±æœ‰å‡ ä¸ªbatch
        analyzed_folder_fp (str): analyzedæ–‡ä»¶å¤¹çš„ç»å¯¹è·¯å¾„
        llm_kwargs (_type_): _description_
        plugin_kwargs (_type_): _description_
        chatbot (_type_): _description_
        history (_type_): _description_
        system_prompt (_type_): _description_
        user_request (_type_): _description_

    Yields:
        _type_: _description_
    """

    # GPTçš„è®¿é—®å‚æ•°
    inputs_array = []
    inputs_show_user_array = []
    history_array = []
    sys_prompt_array = []

    # æœ¬åœ°æ–‡ç« å‚æ•°
    yml_array = []

    # å¤šçº¿ç¨‹é—®GPT
    for index, fp in enumerate(pdf_manifests_fp):   # è·å–æ¯ä¸€ä¸ªpdfæ¸…å•æ–‡ä»¶ï¼Œç”¨äºè¯»å–æ‘˜è¦

        with open(fp, 'r') as f:
            yml_array.append(yaml.safe_load(f))

        # å¦‚æœæ²¡æœ‰æ‘˜è¦ï¼Œå°±è·³è¿‡å§
        abstract = yml_array[index][pdf_yaml.abstract.value]
        if abstract is None:
            continue

        i_say = f"I will provide you with a text next, and you are to analyze and summarize it. \
                There may be some extraneous content within these texts, \
                so please disregard any copyright or authorship information.\
                The text you are to summarize is: {abstract}, and you should focus on these keywords: {', '.join(keywords)}.\
                In addition, if the text mentions any experimental flaws, unmet objectives, \
                or the innovative aspects of the experiment, please also summarize those.\
                While ensuring accuracy and comprehensiveness, \
                use English to condense the summary content as much as possible."

        i_say_show_user = _("[æ‰¹æ¬¡è¿›åº¦ï¼š{a}/{b}] è¯·å¯¹è¿™ç¯‡æ–‡ç« çš„æ‘˜è¦è¿›è¡Œæ€»ç»“æ¦‚æ‹¬\n\nå›´ç»•: {key}").format(
            a=start_batch, b=total_batch, key=', '.join(keywords))

        inputs_array.append(i_say)
        inputs_show_user_array.append(i_say_show_user)
        history_array.append([])
        sys_prompt_array.append('')

    # å¤šçº¿ç¨‹è¯·æ±‚GPT
    if inputs_array is []:     # é’ˆå¯¹è¿™ä¸ªå…³é”®è¯ï¼Œå¦‚æœæ‰€æœ‰æ–‡ç« éƒ½å·²ç»å•ç‹¬åˆ†æè¿‡äº†ï¼Œé‚£ä¹ˆinputs_arrayå°±æ˜¯ç©ºï¼Œä¹Ÿå°±æ²¡æœ‰å¿…è¦è¯·æ±‚GPTäº†
        return

    gpt_response_collection = yield from request_gpt_model_multi_threads_with_very_awesome_ui_and_high_efficiency(
        inputs_array=inputs_array,
        inputs_show_user_array=inputs_show_user_array,
        history_array=history_array,
        sys_prompt_array=sys_prompt_array,
        llm_kwargs=llm_kwargs,
        chatbot=chatbot,
        show_user_at_complete=False
    )

    # gpt_response_collection.extend([inputs_show_user, gpt_res])

    # < -------å›´ç»•æŸä¸ªå…³é”®è¯ã€æ‘˜è¦æ€»ç»“å®Œåï¼ŒæŠŠæ€»ç»“çš„å†…å®¹å†™åˆ°md5.ymlä¸­------------ >

    # éå†GPTè¾“å‡ºçš„ç»“æœ
    yml_index = -1
    for index, content in enumerate(gpt_response_collection):
        # å¥‡æ•°ï¼Œè·å–çš„æ˜¯gpt_resï¼Œé‡Œé¢æ˜¯GPTå¯¹äºå•ä¸ªæ–‡ç« çš„æ€»ç»“å½’çº³
        if index % 2 != 0:  # 1 3 5 7 9 
            # å†™å…¥å½“å‰å…³é”®è¯æ€»ç»“çš„å†…å®¹ï¼ˆæ²¡æœ‰æ‘˜è¦çš„ä¸å†™ï¼‰
            # å¦‚æœæ²¡æœ‰æ‘˜è¦ï¼Œå°±è·³è¿‡å§
            yml_index += 1
            abstract = yml_array[yml_index][pdf_yaml.abstract.value]
            if not abstract is None:
                yml_array[yml_index][pdf_yaml.analysis.value] = content
                with open(pdf_manifests_fp[yml_index], 'w') as f:
                    f.write(yaml.safe_dump(yml_array[yml_index]))


def _summarize_all_paper(this_library_fp: str, llm_kwargs, GPT_prefer_language, chatbot, history, system_prompt, user_request):
    '''
    # ! æ”¹æˆæ¯10ä¸ªæ€»ç»“å†…å®¹ï¼ˆæ•°é‡æˆ–è®¸å¯ä»¥æ›´å¤šç‚¹ï¼Ÿï¼‰è®©LLMè¿›è¡Œåˆ†ææ€»ç»“ã€‚å†…å®¹å¦‚ä¸‹ï¼š
    -   ä»–ä»¬çš„ç ”ç©¶æ–¹å‘ï¼š........ ï¼ˆå°½å¯èƒ½ç®€çŸ­ï¼Œæ¯ä¸€ä¸ªéƒ½è¦æœ‰ï¼‰
    -   è¿™äº›ç ”ç©¶çš„å…±åŒä¹‹å¤„ï¼š........
    -   è¿™äº›ç ”ç©¶çš„å·®å¼‚ç‚¹ï¼š.........
    -   è¿™äº›ç ”ç©¶çš„åˆ›æ–°ä¹‹å¤„:.......
    -   è¿™äº›ç ”ç©¶å¾—åˆ°çš„ç»“è®ºï¼š......,..
    -   è¿™äº›ç ”ç©¶ä¸­å‡ºç°çš„é—®é¢˜æˆ–é”™è¯¯ï¼š........
    
    # ! æ‰€æœ‰çš„10ä¸ªéƒ½åˆ†æå®Œæˆä¹‹åï¼Œé’ˆå¯¹å¾—åˆ°çš„æ€»ç»“å†…å®¹ï¼ŒæŒ‰ç…§ç›¸åŒçš„æ ¼å¼ï¼Œå†æ¬¡æ€»ç»“ã€‚è¿™æ¬¡å°±æ˜¯æŠŠæ¯ä¸ªæ€»ç»“å†…å®¹æ¯ä¸€ä¸ªä¹‹é—´å½¼æ­¤åˆ†æä¸€æ¬¡
    
    # ! è¿™æ ·å­çš„è¯ä¹Ÿå¯ä»¥å®ç°ä¸­æ–­åç»§ç»­åˆ†æï¼Œæ¯•ç«Ÿè®©LLMåˆ†æçš„è¿‡ç¨‹è¿˜æŒºç…ç†¬çš„
    '''
    #  < ---------------------- äº‹å‰å‡†å¤‡ --------------------------- >

    repo_dir = os.path.join(this_library_fp, "repository")

    # è·å–æ‰€æœ‰pdfçš„åˆ†æå†…å®¹
    all_pdf_yml = []  # æ–‡ä»¶åï¼ˆå«æ‹“å±•åï¼‰
    for pdf in os.listdir(repo_dir):
        if pdf.lower().endswith('yml'):
            all_pdf_yml.append(pdf)

    #  < ---------------------- ä»»åŠ¡åˆ†é… --------------------------- >

    if len(all_pdf_yml) == 0:  # æ²¡æœ‰éœ€è¦åˆ†æçš„ä¹Ÿå°±æ²¡å¿…è¦åˆ†æäº†
        return

    # æ¯ä¸ªæ‰¹æ¬¡éœ€è¦æ€»ç»“çš„å†…å®¹ï¼ˆæ¯ä¸ªå…ƒç´ å°±æ˜¯äº”ç¯‡æ–‡ç« çš„åˆ†æå†…å®¹ï¼‰
    batch_content = []

    # å¯¹æ¯5ä¸ªpdfè¿›è¡Œæ€»ç»“åˆ†æ
    # ç¡®å®šèƒ½å¤Ÿåˆ†æˆå¤šå°‘ä¸ªæ‰¹æ¬¡
    num_batches = len(all_pdf_yml) // 5 if len(all_pdf_yml) >= 5 else 1

    for i in range(num_batches):
        start_index = i * 5
        # è¿˜æ²¡æœ‰åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„batchï¼Œbatch  5ä¸ªå†…å®¹å°±å¯ä»¥
        if i < num_batches - 1:
            end_index = (i + 1) * 5
            batch = all_pdf_yml[start_index:end_index]
        # åˆ°äº†æœ€åä¸€ä¸ªbatchäº†ï¼Œå°±æŠŠå‰©ä¸‹ä¸è¶³5ä¸ªçš„å†…å®¹ä¹Ÿå½’çº³è¿›æ¥ï¼Œå°±æ˜¯æœ€åä¸€ä¸ªbatchå¯èƒ½æœ‰åå¤šä¸ªå†…å®¹äº†
        else:
            batch = all_pdf_yml[start_index:]

        content = ''
        for index, yml_each_batch in enumerate(batch):
            with open(os.path.join(repo_dir, yml_each_batch)) as yml:
                content = f'{content} \n\n   {yaml.safe_load(yml)[pdf_yaml.analysis.value]}'
        batch_content.append(content)

    #  < ---------------------- å¯¹åˆ†é…ä¸‹å»çš„å†…å®¹è¿›è¡Œæ€»ç»“ --------------------------- >

    input_array = []
    prompt_array = []
    history_array = []
    inputs_show_user_array = []
    input = ''

    prompt = 'You are good at summarizing and analyzing. When answering my questions, try to be as detailed as possible.\
            And, please remember to respond to me in English.\
            Ensure that your thinking process includes a thorough examination of \
            what materials or tools were used, what was done, why it was done that way, \
            and what the significance or potential drawbacks of this approach are.\
            Please donnot specify which study it is, as they may have similarities. Use JSON and reply to me in this format (markdown):\n \
                    - Research Direction\n\
                    - The Commonalities in These Studies\n\
                    - Differences in These Studies\n\
                    - Innovative Aspects of These Studies\
                    - Conclusions from These Studies\n\
                    - Issues or Errors in These Studies'

    for content in batch_content:

        input = f'There are now five research topics: {content}. Please answer my questions based on these topics:\
                1. What are the research directions of these studies? please provide a brief answer for each.\
                2. What are the commonalities among these studies?\
                3. What are the differences among these studies?\
                4. What innovative aspects do these studies have?\
                5. What conclusions have these studies drawn (as detailed as possible)?\
                6. What issues, errors, or shortcomings have been mentioned in these studies?'

        prompt_array.append(prompt)
        input_array.append(input)
        history_array.append('')
        inputs_show_user_array.append(_('å¤„ç†ä¸­...'))

    gpt_say = yield from request_gpt_model_multi_threads_with_very_awesome_ui_and_high_efficiency(
        inputs_array=input_array,
        inputs_show_user_array=inputs_show_user_array,
        llm_kwargs=llm_kwargs,
        chatbot=chatbot,
        history_array=history_array,
        sys_prompt_array=prompt_array,
    )

    yield from update_ui_lastest_msg(_('å¤šçº¿ç¨‹æ“ä½œå®Œæˆ'), chatbot=chatbot, history=[])
    #  < ---------------------- å¯¹æ¯ä¸€ä¸ªæ‰¹æ¬¡æ€»ç»“å¾—åˆ°çš„å†…å®¹è¿›è¡Œåˆå¹¶ --------------------------- >

    batch_analysis_content = ''
    for index, s in enumerate(gpt_say):
        if index % 2 == 1:
            batch_analysis_content = f'{batch_analysis_content}\n\n{s}'

    input = f'I will give you a large batch of similar JSONs.\
        Can you merge them into one JSON without modifying, removing, or adding any content, \
            and without changing the structure of the JSON? Thank you. \
                Here is the batch of JSONs for you: {"  ".join(batch_analysis_content)}'

    # combine = yield from request_gpt_model_in_new_thread_with_ui_alive(
    #     inputs=input,
    #     inputs_show_user=_('åˆå¹¶ä¼˜åŒ–ä¸­...'),
    #     llm_kwargs=llm_kwargs,
    #     chatbot=chatbot,
    #     history=[],
    #     sys_prompt=prompt
    # )
    # yield from update_ui_lastest_msg(_('ä¼˜åŒ–å®Œæˆ'), chatbot=chatbot, history=[])
    combine = "  ".join(batch_analysis_content)

    #  < ---------------------- æœ€åçš„å¤„ç†ï¼Œå‡†å¤‡è¾“å‡ºå†…å®¹ï¼ˆä½¿ç”¨åå¥½è¯­è¨€ï¼‰ --------------------------- >

    input = f'I will provide you with a JSON file. \
            Please remove any duplicated content and then provide a comprehensive summary at the end. \
            Present the result in a visually appealing Markdown format, \
            and please provide me with the processed results directly, without any other information. \
            The JSON is as follows: {combine}'
    gpt_summary = yield from request_gpt_model_in_new_thread_with_ui_alive(
        inputs=input,
        inputs_show_user=_('æœ€åæ€»ç»“ä¸­.....'),
        llm_kwargs=llm_kwargs,
        chatbot=chatbot,
        history=[],
        sys_prompt=f'please answer me in {GPT_prefer_language}. Please just show me the Markdown, without using code blocks (````). I want to see the rendered result of the Markdown.'
    )

    yield from update_ui_lastest_msg(_('æ€»ç»“å®Œæˆ'), chatbot=chatbot, history=[])
    return gpt_summary


def _unusable_pdf_message(lib_dir:str,unusable_pdf_fp: str = None):
    # é¢„å¤„ç†ï¼ˆå¾—åˆ°DOIæ ‡é¢˜å•¥çš„ï¼‰é‚£é‡Œæé†’ä¸€æ¬¡
    # æ€»ç»“ç»“æŸé‚£é‡Œå†æé†’ä¸€æ¬¡
    # ä¹Ÿæä¾›ä¸€ä¸‹ä¸‹è½½ï¼Œè®©ç”¨æˆ·çŸ¥é“æ˜¯å“ªä¸ªæ–‡ç« ä¸èƒ½ç”¨
    # åŒæ ·çš„ï¼Œæ”¯æŒä¸­æ–­
    
    unusable_pdf_yml_content = {'latest_datetime':datetime.now().strftime("%Y-%m-%d %H-%M-%S"), # å› ä¸ºæ”¯æŒä¸­æ–­ï¼Œæ‰€ä»¥è®°å½•æœ€æ–°çš„æ›´æ–°æ—¥æœŸ
                                'preprocess_done':False, # æ‰€æœ‰çš„é¢„å¤„ç†å®Œæˆäº†å—ï¼Ÿ
                                'scholar_navis_version':VERSION,
                                'reason':'Chinese dissertations, encrypted files, non-PDF files or damaged files',
                                'list':[]}

    unusable_pdf_yml_fp = os.path.join(lib_dir,'unusable_pdf_list.yml')
    
    if not os.path.exists(unusable_pdf_yml_fp):
        with open(unusable_pdf_yml_fp,'w',encoding='utf-8') as f:
            f.write(yaml.safe_dump(unusable_pdf_yml_content))
            
    # è®°å½•è¿™äº›ä¸èƒ½ç”¨çš„æ–‡ç« ï¼Œç”Ÿæˆä¸€ä¸ªtxtï¼Œä¾¿äºåé¢çš„æç¤ºå’Œä¸‹è½½
    with open(unusable_pdf_yml_fp,'r',encoding='utf-8') as f:
        unusable_pdf_yml_content = yaml.safe_load(f)
    
    # æ–°äº§ç”Ÿçš„æ— ç”¨PDF
    if unusable_pdf_fp:
        # æŠŠæ–°çš„ï¼Œä¸é‡å¤çš„æ·»åŠ è¿›æ¥
        if unusable_pdf_fp not in unusable_pdf_yml_content['list']:
            unusable_pdf_yml_content['list'].append(unusable_pdf_fp)
            unusable_pdf_yml_content['latest_datetime'] = datetime.now().strftime("%Y-%m-%d %H-%M-%S") # è®°å½•æ›´æ–°æ—¥æœŸ
    # æ²¡æœ‰æ–°äº§ç”Ÿçš„ï¼Œå°±ç”¨ä¹‹å‰ä¿å­˜çš„æç¤ºã€‚åæ­£ä¸èƒ½æ·»åŠ æ–°çš„æ–‡ç« äº†
    else:
        unusable_pdf_yml_content['preprocess_done'] = True

    # è®°å½•å’¯
    with open(unusable_pdf_yml_fp,'w',encoding='utf-8') as f:
        f.write(yaml.safe_dump(unusable_pdf_yml_content))

    if len(unusable_pdf_yml_content['list']) > 0:
        download_list = '<ul>\n'
        for file in unusable_pdf_yml_content['list']:
            download_list +=  f'<li>{generate_download_file(file)}</li>\n'
        download_list += '\n</ul>'
        return [_('å­˜åœ¨ä¸å¯ä½¿ç”¨çš„PDFï¼ˆä¸­æ–‡å­¦ä½è®ºæ–‡ã€åŠ å¯†æ–‡ä»¶ã€éPDFæ–‡ä»¶æˆ–æŸåæ–‡ä»¶ï¼‰ï¼Œè¿™äº›æ–‡ä»¶ä¸ä¼šå‚ä¸æ€»ç»“ã€‚æ–‡ä»¶å¦‚ä¸‹ï¼š'),download_list]
    else: return [_('å…¨éƒ¨PDFå¯ç”¨ï¼'),_('ä¸å­˜åœ¨ä¸å¯ç”¨çš„PDF')]
        
class Summarize_Articles_Keywords(common_plugin_para):
    def define_arg_selection_menu(self):
        gui_definition = super().define_arg_selection_menu()
        gui_definition.update(self.add_lib_field(False))
        gui_definition.update(self.add_GPT_prefer_language_selector())
        gui_definition.update(self.add_command_selector(['force'], [_('å¼ºåˆ¶é‡æ–°åˆ†æ')], [False]))
        gui_definition.update(self.add_use_AI_assistant_selector())
        return gui_definition

    def execute(txt, llm_kwargs, plugin_kwargs, chatbot, history, system_prompt, user_request):
        yield from æŒ‰å…³é”®è¯æ€»ç»“æ–‡çŒ®(txt, llm_kwargs,plugin_kwargs,chatbot,history,system_prompt,user_request)